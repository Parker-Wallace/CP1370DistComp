
# Lab 8: Cube, Rollup, Sliding Window grouping and Window functions
> Total 25 marks, Due Friday March 14th
1. (5 marks) The file mpg.csv contains data about various automobiles. Load this file into a dataframe and perform the following:
    - Filter the dataframe to only include 'ford' and 'dodge' vehicles
    - Perform a Rollup on the manufacturer and number of cylinders columns, which displays the total vehicles from that manufacturer with the given number of cylinders. Be sure to order the rows so the null values are contained last.
    - Perform the same steps using the Cube function instead of Rollup
2. (5 marks) #The file aapl-2017.csv contains information about daily apple stock prices. Load this file into a dataframe and perform the following:
    - Calculate the monthy average closing price using a window function inside the groupBy transformation. For the window function, use a sliding window which slides by 1 week at a time. Be sure to order the results in ascending order by the start date of the window
    - Output the start time, end time for the window as well as the monthly average 

### Exercises 3-5 Window Functions ( Use the following data )

> This code loads bicycle sales data for 1 week from 4 local bike shops:
```python
data = [
("2025-01-01", "Eric's Bikes",  "Norco Storm",          4500.75),
("2025-01-01", "Eric's Bikes",  "Cannondale Optimo",    5200.50),
("2025-01-01", "CNA Bikes",     "Specialized S-Works",  4800.25),
("2025-01-01", "CNA Bikes",     "Trek Madone",          4600.10),
("2025-01-01", "Canary Cycles", "Norco Storm",          5100.95),
("2025-01-01", "Canary Cycles", "Cannondale Optimo",    4750.60),
("2025-01-02", "Eric's Bikes",  "Norco Storm",          4450.00),
("2025-01-02", "Eric's Bikes",  "Specialized S-Works",  5350.30),
("2025-01-02", "CNA Bikes",     "Trek Madone",          4300.75),
("2025-01-02", "CNA Bikes",     "Cannondale Optimo",    4900.20),
("2025-01-02", "Canary Cycles", "Norco Storm",          5500.00),
("2025-01-02", "Canary Cycles", "Specialized S-Works",  5600.40),
("2025-01-03", "Eric's Bikes",  "Cannondale Optimo",    5100.30),
("2025-01-03", "Eric's Bikes",  "Trek Madone",          4500.90),
("2025-01-03", "CNA Bikes",     "Norco Storm",          5200.75),
("2025-01-03", "CNA Bikes",     "Specialized S-Works",  5450.80),
("2025-01-03", "Canary Cycles", "Norco Storm",          5700.40),
("2025-01-03", "Canary Cycles", "Trek Madone",          4600.50),
("2025-01-04", "Eric's Bikes",  "Norco Storm",          4800.60),
("2025-01-04", "Eric's Bikes",  "Specialized S-Works",  5000.80),
("2025-01-04", "CNA Bikes",     "Trek Madone",          4800.25),
("2025-01-04", "CNA Bikes",     "Cannondale Optimo",    4700.10),
("2025-01-04", "Canary Cycles", "Norco Storm",          5400.85),
("2025-01-04", "Canary Cycles", "Specialized S-Works",  5100.60),
("2025-01-05", "Eric's Bikes",  "Cannondale Optimo",    5300.40),
("2025-01-05", "Eric's Bikes",  "Trek Madone",          4500.35),
("2025-01-05", "CNA Bikes",     "Norco Storm",          4700.50),
("2025-01-05", "CNA Bikes",     "Specialized S-Works",  5200.00),
("2025-01-05", "Canary Cycles", "Norco Storm",          5500.90),
("2025-01-05", "Canary Cycles", "Cannondale Optimo",    4950.10)
]
# Define schema
schema = StructType([
StructField("date", StringType(), True),
StructField("store", StringType(), True),
StructField("product", StringType(), True),
StructField("sales_amount", DoubleType(), True)
])
# Create DataFrame
df = spark.createDataFrame(data, schema)
```
3. (5 marks) Rank the sales within within each store based on the sales amount column
    - create a window specification to partition the data by store and order by sales_amount in descending order. Make sure you are including all rows (use the rowsBetween method)
    - use the rank() function to assign ranks to each product and add this column to the dataFrame
4. (5 marks) Calculate the running total of Sales amounts per store
    - Create a window specification to partition the data by store and order by date in ascending order. Make sure you are including rows from the start of the window up to the current row ( use the rowsBetween method )
    - Use the sum() function as a window function to calculate the running total and add this column to the dataFrame
5. (5 marks) Calculate the average sales per store for the last 3 days
    - Create a window specification to partition the data by store and order by date in ascending order. Make sure you are including rows from 2 days before the current date up to the current date ( use the rowsBetween method).
    - Use the avg function to compute the average from the sales amount column and add this column to the dataFrame
